### Cornelia feedback

- Title, Authors 
- (15%) Motivation: Identifies previous work done (nice!). ML in climate change is new area of research (itâ€™s true, a lot of research is directed in this direction these days). 
- (15%) Data: Love the graph. Clear distinction between features and output (average annual temperature change relative to baseline years). The data is panel (year and country information). The team looked into El Nino and La Nina - a feedback they received during the baseline presentation. Preprocessing: identified that there is some missing data, split into train/val/test is not random (good). EDA: love the total emissions plots by region. Feature selection: 
- (15%) Modeling: The presentation is very clear: tried 6 models and used RMSE and MAE to evaluate performance (nice!). Tested differences between models using a t-test (very nice!) LR model does best (I am not surprised, LR is usually best with this type of data). I am not sure if the prediction error is small or not (what is the mean value of your outcome in the data?). 
- (30%) Experiments: yes (LR, FFNN)
- (10%) Conclusions: best performing model was LR. Future work: LSTMs. I liked that the team was transparent in terms of what their models can do in terms of prediction performance and mentioned that climate modeling is not an easy task and further work is needed.
- (15%) Code submission: very well commented and organized, clearly team work.
- Contributions: TBD
